{
 "metadata": {
  "name": "",
  "signature": "sha256:faf6042707a7e2d0721ea989a26727ad73d308febba76df6b71af0c7c4b1ceca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats as stats\n",
      "import numpy as np\n",
      "from numpy.linalg import svd\n",
      "import pickle\n",
      "\n",
      "# load the data\n",
      "file_p = open('../data/dom-cnt-matrix.data', 'r')\n",
      "countries, sites, site_cnt = pickle.load(file_p)\n",
      "file_p.close()\n",
      "\n",
      "# load the domain to category lookups\n",
      "dom2cat, cat2dom = {}, {}\n",
      "with open('../data/domain-to-cat-2015-march-27.txt', 'r') as filep:\n",
      "    for line in filep.readlines():\n",
      "        domain, cats = line.strip().split(',')\n",
      "        cats = cats.split('|')\n",
      "        dom2cat[domain] = cats\n",
      "        for cat in cats:\n",
      "            if cat not in cat2dom:\n",
      "                cat2dom[cat] = {}\n",
      "            cat2dom[cat][domain] = True\n",
      "            \n",
      "# load the country to region tables\n",
      "cnt2reg, reg2cnt, reg2name = {}, {}, {}\n",
      "with open('../../utility/imf-region-to-country.txt', 'r') as filep:\n",
      "    for line in filep.readlines():\n",
      "        reg, cc = line.strip().split(',')\n",
      "        cnt2reg[cc] = reg\n",
      "        if reg not in reg2cnt:\n",
      "            reg2cnt[reg] = {}\n",
      "        reg2cnt[reg][cc] = True\n",
      "with open('../../utility/imf-region-names.txt', 'r') as filep:\n",
      "    for line in filep.readlines():\n",
      "        reg, abrev = line.strip().split(',')\n",
      "        reg2name[abrev] = reg\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "\n",
      "def center(a, scale=True, axis=0):\n",
      "    \"\"\"Center the matrix so that units don't matter by subtracting the mean and\n",
      "    dividing by the standard deviation\n",
      "    \n",
      "    Again, this won't tell us the most commonly censored sites, this will tell us\n",
      "    which sites are commonly censored together\n",
      "    \n",
      "    \"\"\"\n",
      "    b = np.array(a, copy=True)\n",
      "    mean = a.mean(axis=axis)\n",
      "    b -= mean\n",
      "    if scale:\n",
      "        std = b.std(axis=axis)\n",
      "        std = np.where( std, std, 1. )\n",
      "        b /= std\n",
      "    return b\n",
      "    \n",
      "\n",
      "# compute the principal components\n",
      "center_obj = center(site_cnt)\n",
      "U, s, Vt = svd(center_obj)\n",
      "\n",
      "V = Vt.T\n",
      "\n",
      "\n",
      "# print some info about the top few principal components\n",
      "print \"Variance explained, mean, std dev of vector\"\n",
      "for index in range(10):\n",
      "    var_exp = s[index] * s[index] / float(len(countries))\n",
      "    mean = stats.tmean(V[:, index])\n",
      "    var = stats.tvar(V[:, index])\n",
      "    # compute how many elements are really present in the vector\n",
      "    stuff = [1 for x in V[:, index] if math.fabs(x) > 0.05]\n",
      "    \n",
      "    # print it all out\n",
      "    print \"{:< .5e}, {:< .5e}, {:< .5e}, {}\".format(var_exp, mean, var, len(stuff))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variance explained, mean, std dev of vector\n",
        " 1.70293e+02,  2.40756e-02,  1.17991e-03, 173\n",
        " 3.72949e+01,  1.45665e-02,  1.54801e-03, 56\n",
        " 3.37039e+01, -8.87277e-03,  1.68170e-03, 38\n",
        " 2.78671e+01,  8.23854e-03,  1.69257e-03, 41\n",
        " 1.06622e+01, -1.00464e-04,  1.76055e-03, 47\n",
        " 7.35952e+00,  3.48014e-03,  1.74843e-03, 12\n",
        " 6.61281e+00, -3.31387e-03,  1.74956e-03, 19\n",
        " 6.55320e+00, -7.83998e-04,  1.75995e-03, 18\n",
        " 5.42480e+00, -2.57140e-03,  1.75394e-03, 14\n",
        " 5.33543e+00,  4.45556e-03,  1.74068e-03, 17\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "import pprint\n",
      "# let's explore the individual components in more depth by printing the top 9 components (don't care about first component)\n",
      "for index in range(0, 10):\n",
      "    mean = stats.tmean(V[:, index])\n",
      "    indices = [x for x in range(len(V[:, index])) if math.fabs(V[x, index]) > 0.05]\n",
      "    site_list = [sites[x] for x in indices]\n",
      "    counter = collections.Counter()\n",
      "    for site in site_list:\n",
      "        cats = dom2cat[site]\n",
      "        for cat in cats:\n",
      "            counter[cat] += 1\n",
      "    print \"Component \" + str(index) + \": \" +\", \".join(site_list) + \"\\n\"\n",
      "    print sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
      "    print\n",
      "    entries = {}\n",
      "    for site in site_list:\n",
      "        cats = dom2cat[site]\n",
      "        for cat in cats:\n",
      "            if cat not in entries:\n",
      "                entries[cat] = []\n",
      "            entries[cat].append(site)\n",
      "    #pprint.pprint(entries)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Component 0: 000webhost.com, 24hourfitness.com, 6pm.com, 9gag.com, aa.com, accuweather.com, adp.com, alarabiya.net, allrecipes.com, americanexpress.com, ancestry.com, ask.com, att.com, authoritynutrition.com, autotrader.com, bankrate.com, bedbathandbeyond.com, bettycrocker.com, bhg.com, biblegateway.com, biblehub.com, boardgamegeek.com, brainyquote.com, btc-e.com, cafemom.com, capitalone.com, caranddriver.com, cartoonnetwork.com, cbsnews.com, chess.com, chron.com, coinbase.com, constantcontact.com, costco.com, cracked.com, cricbuzz.com, cupcakebridge.com, curse.com, cvs.com, deadspin.com, deviantart.com, dieburger.com, discogs.com, dorkly.com, drudgereport.com, dx.com, easyjet.com, economist.com, edmunds.com, ejabat.google.com, elance.com, elsevier.com, emedicine.medscape.com, ew.com, expedia.com, fantasy.nfl.com, fatakat.com, fifa.com, findagrave.com, fontsquirrel.com, foodnetwork.com, fool.com, forbes.com, ford.com, forever21.com, gaiaonline.com, get.ironsocket.com, girlsgogames.com, givemesport.com, go.com, goldenfrog.com, groupon.com, grubhub.com, gsmarena.com, hawaaworld.com, hdfcbank.com, hilton.com, hindustantimes.com, icy-veins.com, ign.com, imgur.com, individual.com, infowars.com, instructables.com, jcpenney.com, jeddahbikers.com, justanswer.com, jw.org, kohls.com, kooora.com, kyknet.dstv.com, landbou.com, latimes.com, legacy.com, livescience.com, lufthansa.com, macys.com, mail.live.com, makeupalley.com, maktoob.com, mathworks.com, medcohealth.com, menshealth.com, mercola.com, merriam-webster.com, metacritic.com, mmo-champion.com, mnn.com, myegy.com, n4g.com, nationalgeographic.com, nature.com, nba.com, nick.com, nintendo.com, office.com, online.citibank.com, opendns.com, paulaschoice.com, pcgamer.com, pch.com, petmd.com, phonearena.com, popsci.com, premierleague.com, prevention.com, psychologytoday.com, quikr.com, rakuten.com, rockstargames.com, rollingstone.com, royalmail.com, sciencedirect.com, scout.com, sheknows.com, shopathome.com, siteadvisor.com, snopes.com, space.com, spine-health.com, spotify.com, square-enix.com, stackoverflow.com, stardoll.com, store.apple.com, store.steampowered.com, t-mobile.com, target.com, thefind.com, thehindu.com, theknot.com, thesaurus.com, thrillist.com, top10homeremedies.com, translate.google.com, travelocity.com, travelzoo.com, ultimate-guitar.com, usnews.com, verizon.com, virgin-atlantic.com, virtua-fighter-4.com, walgreens.com, wellsfargo.com, whitepages.com, wordpress.com, www.udemy.com, xbox.com, y8.com, yellowpages.sulekha.com, zappos.com, zara.com, zocdoc.com\n",
        "\n",
        "[('business', 24), ('regional', 24), ('kids_and_teens', 21), ('home', 20), ('games', 19), ('shopping', 17), ('world', 16), ('recreation', 15), ('society', 15), ('health', 15), ('science', 15), ('news', 14), ('arts', 13), ('sports', 12), ('computers', 10), ('reference', 9), ('vpn', 2), ('circum', 1)]\n",
        "\n",
        "Component 1: adam4adam.com, adameve.com, asexstories.com, askmen.com, asstr.org, aventertainments.com, celebritymoviearchive.com, clips4sale.com, cosmopolitan.com, debonairblog.com, digitalplayground.com, dit-inc.us, fabswingers.com, femjoy.com, fetlife.com, flirt4free.com, freeones.com, ftvgirls.com, games.espn.go.com, gayromeo.com, girlfriendvideos.com, hentai-foundry.com, hsselite.com, hulu.com, iafd.com, imlive.com, indiansexstories.net, livejasmin.com, livescore.com, manhunt.net, metacafe.com, mrskin.com, netflix.com, newgrounds.com, nudevista.com, oglaf.com, payserve.com, planetsuzy.org, popsugar.com, proxify.com, purevpn.com, scribd.com, shooshtime.com, soccerway.com, squirt.org, streamate.com, suicidegirls.com, thehun.net, tv.yahoo.com, vice.com, victoriassecret.com, videosexarchive.com, voyeurweb.com, worldsex.com, xcams.com, youporn.com\n",
        "\n",
        "[('adult', 39), ('arts', 5), ('society', 4), ('sports', 3), ('vpn', 3), ('computers', 2), ('shopping', 2), ('business', 1), ('regional', 1), ('recreation', 1), ('world', 1), ('circum', 1)]\n",
        "\n",
        "Component 2: alexa.com, alkasir.com, archive.org, bitcointalk.org, blogger.com, docs.google.com, equalit.ie, express-vpn.com, facebook.com, flickr.com, food.com, freenetproject.org, getlantern.org, hidemyass.com, hotspotshield.com, ibvpn.com, ipvanish.com, msn.com, nordvpn.com, ooni.torproject.org, plus.google.com, psiphon.ca, reuters.com, safervpn.com, strongvpn.com, torproject.org, tunnelbear.com, twitter.com, uproxy.org, vpnintouch.com, w3.org, www.dropbox.com, www.facebook.com, www.samsung.com, www.youtube.com, your-freedom.net, youtube.com, zh.greatfire.org\n",
        "\n",
        "[('computers', 13), ('circum', 10), ('vpn', 10), ('world', 9), ('regional', 4), ('arts', 3), ('business', 2), ('reference', 2), ('science', 1), ('society', 1), ('home', 1), ('news', 1)]\n",
        "\n",
        "Component 3: 9gag.com, addictinggames.com, azlyrics.com, battle.net, bulbagarden.net, bungie.net, cafemom.com, cartoonnetwork.com, complex.com, crypto.cat, curse.com, deezer.com, ea.com, furaffinity.net, gamesradar.com, girlsgogames.com, hattrick.org, hollywoodlife.com, kidshealth.org, king.com, kongregate.com, leagueoflegends.com, livejournal.com, marriott.com, metacritic.com, minecraft.net, minecraftforum.net, miniclip.com, myegy.com, npr.org, pbskids.org, pcgamer.com, pinterest.com, planetminecraft.com, rsg.co.za, shareasale.com, soundcloud.com, store.steampowered.com, stumbleupon.com, wizards.com, y8.com\n",
        "\n",
        "[('games', 18), ('kids_and_teens', 15), ('arts', 7), ('computers', 4), ('world', 4), ('health', 3), ('recreation', 2), ('regional', 2), ('society', 2), ('shopping', 1), ('reference', 1), ('business', 1), ('sports', 1), ('circum', 1), ('home', 1), ('news', 1), ('adult', 1)]\n",
        "\n",
        "Component 4: asexstories.com, askmen.com, asstr.org, aventertainments.com, celebritymoviearchive.com, clips4sale.com, cosmopolitan.com, digitalplayground.com, dit-inc.us, fabswingers.com, femjoy.com, fetlife.com, flirt4free.com, games.espn.go.com, gayromeo.com, girlfriendvideos.com, hsselite.com, hulu.com, iafd.com, imlive.com, indiansexstories.net, livejasmin.com, livescore.com, manhunt.net, metacafe.com, mrskin.com, netflix.com, newgrounds.com, payserve.com, planetsuzy.org, popsugar.com, proxify.com, purevpn.com, scribd.com, shooshtime.com, soccerway.com, squirt.org, thehun.net, timeout.com, tv.yahoo.com, vice.com, victoriassecret.com, videosexarchive.com, voyeurweb.com, williamhill.com, xcams.com, xnxx.com\n",
        "\n",
        "[('adult', 28), ('arts', 6), ('society', 4), ('sports', 3), ('vpn', 3), ('computers', 2), ('shopping', 2), ('regional', 2), ('recreation', 2), ('business', 1), ('games', 1), ('world', 1), ('circum', 1)]\n",
        "\n",
        "Component 5: cam4.com, costco.com, epicurious.com, equalit.ie, indeed.com, mensfitness.com, paypal.com, self.com, startimes.com, totalbeauty.com, virgin-atlantic.com, wired.com\n",
        "\n",
        "[('business', 3), ('health', 3), ('computers', 2), ('home', 2), ('recreation', 1), ('shopping', 1), ('regional', 1), ('arts', 1), ('adult', 1), ('world', 1), ('circum', 1)]\n",
        "\n",
        "Component 6: addictinggames.com, bungie.net, ea.com, eonline.com, equalit.ie, gamesradar.com, indeed.com, leagueoflegends.com, miniclip.com, nudevista.com, oglaf.com, reddit.com, rockstargames.com, sherdog.com, suicidegirls.com, timeout.com, vimeo.com, vintage-erotica-forum.com, xbox.com\n",
        "\n",
        "[('games', 10), ('kids_and_teens', 4), ('adult', 4), ('arts', 2), ('business', 2), ('computers', 1), ('regional', 1), ('recreation', 1), ('sports', 1), ('circum', 1), ('world', 1), ('news', 1)]\n",
        "\n",
        "Component 7: addictinggames.com, bungie.net, ea.com, eonline.com, equalit.ie, gamesradar.com, leagueoflegends.com, miniclip.com, nudevista.com, oglaf.com, reddit.com, rockstargames.com, sherdog.com, suicidegirls.com, vimeo.com, vintage-erotica-forum.com, www.etsy.com, xbox.com\n",
        "\n",
        "[('games', 10), ('kids_and_teens', 4), ('adult', 4), ('arts', 1), ('computers', 1), ('shopping', 1), ('business', 1), ('regional', 1), ('sports', 1), ('circum', 1), ('world', 1), ('news', 1)]\n",
        "\n",
        "Component 8: economictimes.indiatimes.com, ejabat.google.com, foodandwine.com, fool.com, google.com, gq.com, hollywoodlife.com, mail.google.com, maps.google.com, mlb.mlb.com, navbharattimes.indiatimes.com, news.nationalgeographic.com, timesofindia.indiatimes.com, us.playstation.com\n",
        "\n",
        "[('world', 10), ('computers', 4), ('regional', 3), ('society', 3), ('news', 3), ('business', 2), ('kids_and_teens', 2), ('home', 2), ('recreation', 1), ('shopping', 1), ('reference', 1), ('sports', 1), ('games', 1), ('science', 1)]\n",
        "\n",
        "Component 9: economictimes.indiatimes.com, ejabat.google.com, foodandwine.com, fool.com, google.com, gq.com, hollywoodlife.com, indeed.com, mail.google.com, maps.google.com, mlb.mlb.com, navbharattimes.indiatimes.com, news.nationalgeographic.com, tails.boum.org, timesofindia.indiatimes.com, us.playstation.com, victoriassecret.com\n",
        "\n",
        "[('world', 10), ('computers', 4), ('business', 3), ('regional', 3), ('society', 3), ('news', 3), ('shopping', 2), ('kids_and_teens', 2), ('home', 2), ('recreation', 1), ('reference', 1), ('sports', 1), ('games', 1), ('circum', 1), ('science', 1)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now try clustering together similar countries\n",
      "\n",
      "cnt_site = center(site_cnt.T)\n",
      "Uc, sc, Vtc = svd(cnt_site)\n",
      "\n",
      "Vc = Vtc.T\n",
      "\n",
      "\n",
      "# print some info about the top few principal components\n",
      "print \"Variance explained, mean, std dev of vector\"\n",
      "for index in range(10):\n",
      "    var_exp = sc[index] * sc[index] / float(len(sites))\n",
      "    mean = stats.tmean(Vc[:, index])\n",
      "    var = stats.tvar(Vc[:, index])\n",
      "    # compute how many elements are really present in the vector\n",
      "    stuff = [1 for x in Vc[:, index] if math.fabs(x) > 0.05]\n",
      "    \n",
      "    # print it all out\n",
      "    print \"{:< .5e}, {:< .5e}, {:< .5e}, {}\".format(var_exp, mean, var, len(stuff))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variance explained, mean, std dev of vector\n",
        " 4.54372e+01,  6.01353e-02,  3.20829e-03, 70\n",
        " 2.58488e+01, -3.87253e-02,  5.33939e-03, 48\n",
        " 1.80411e+01,  2.19470e-02,  6.36435e-03, 27\n",
        " 1.38244e+01,  3.79366e-03,  6.83482e-03, 75\n",
        " 8.22722e+00, -9.28641e-03,  6.76249e-03, 66\n",
        " 4.24289e+00, -5.04099e-03,  6.82373e-03, 30\n",
        " 2.09285e+00,  3.79234e-03,  6.83483e-03, 28\n",
        " 1.86906e+00,  4.45204e-03,  6.82936e-03, 18\n",
        " 1.31403e+00,  5.24401e-03,  6.82163e-03, 23\n",
        " 1.25001e+00, -1.05873e-03,  6.84819e-03, 23\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('../../utility/imf-region-to-country.txt', 'r') as filep:\n",
      "    for line in filep.readlines():\n",
      "        reg, cc = line.strip().split(',')\n",
      "        cnt2reg[cc] = reg\n",
      "        if reg not in reg2cnt:\n",
      "            reg2cnt[reg] = {}\n",
      "        reg2cnt[reg][cc] = True\n",
      "\n",
      "\n",
      "\n",
      "import collections\n",
      "from incf.countryutils import transformations\n",
      "import pprint\n",
      "# let's explore the individual components in more depth by printing the top 9 components \n",
      "for index in range(0, 10):\n",
      "    mean = stats.tmean(Vc[:, index])\n",
      "    indices = [x for x in range(len(Vc[:, index])) if math.fabs(Vc[x, index]) > 0.05]\n",
      "    cnt_list = [countries[x] for x in indices]\n",
      "#    cnt_names = [transformations.cc_to_cn(x) for x in cnt_list]\n",
      "    reg_cnts = collections.Counter([reg2name[cnt2reg[x.lower()]] for x in cnt_list if x != \"N/A\"])\n",
      "\n",
      "    cnt_names = []\n",
      "    for x in cnt_list:\n",
      "        if x == \"N/A\":\n",
      "            continue\n",
      "        cnt_names.append(transformations.cc_to_cn(x))\n",
      "    explained_var = sc[index] * sc[index] / float(len(sites))\n",
      "    print \"Component {}: explained var: {} countries: {}\".format(index, explained_var, \", \".join(cnt_list))\n",
      "    print \", \".join(cnt_names) + \"\\n\"\n",
      "    print sorted(reg_cnts.items(), key=lambda x: x[1], reverse=True)\n",
      "    print\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Component 0: explained var: 45.43716257 countries: AD, AE, AL, AT, AU, AX, AZ, BA, BE, BG, BH, BW, BY, CH, CZ, DE, DK, EE, EG, ES, FI, FR, GB, GH, GM, GR, HK, HU, IE, IL, IN, IS, IT, JE, JP, KW, KZ, LB, LT, LU, LV, MD, ME, MK, MY, N/A, NA, NG, NL, NO, NZ, PH, PK, PL, PT, RO, RS, RU, SA, SE, SG, SI, SK, TR, TW, UA, UZ, VN, ZA, ZW\n",
        "Andorra, United Arab Emirates, Albania, Austria, Australia, \u00c5land Islands, Azerbaijan, Bosnia and Herzegovina, Belgium, Bulgaria, Bahrain, Botswana, Belarus, Switzerland, Czech Republic, Germany, Denmark, Estonia, Egypt, Spain, Finland, France, United Kingdom of Great Britain & Northern Ireland, Ghana, Gambia, Greece, Hong Kong, Hungary, Ireland, Israel, India, Iceland, Italy, Jersey, Japan, Kuwait, Kazakhstan, Lebanon, Lithuania, Luxembourg, Latvia, Moldova, Montenegro, Macedonia, Malaysia, Namibia, Nigeria, Netherlands, Norway, New Zealand, Philippines, Pakistan, Poland, Portugal, Romania, Serbia, Russian Federation, Saudi Arabia, Sweden, Singapore, Slovenia, Slovakia (Slovak Republic), Turkey, Taiwan, Ukraine, Uzbekistan, Vietnam, South Africa, Zimbabwe\n",
        "\n",
        "[('Europe', 40), ('Asia', 21), ('Africa', 7), ('Middle_East', 1)]\n",
        "\n",
        "Component 1: explained var: 25.8488429926 countries: AE, AG, AR, AU, BD, BM, BO, BR, BS, BT, CA, CL, CO, CR, DO, EC, GT, GU, HK, HN, ID, IN, JP, KH, KR, MN, MO, MX, MY, NI, NZ, OM, PE, PF, PH, PM, PR, PW, QA, SG, SV, TH, TL, TO, TW, US, VE, VN\n",
        "United Arab Emirates, Antigua and Barbuda, Argentina, Australia, Bangladesh, Bermuda, Bolivia, Brazil, Bahamas, Bhutan, Canada, Chile, Colombia, Costa Rica, Dominican Republic, Ecuador, Guatemala, Guam, Hong Kong, Honduras, Indonesia, India, Japan, Cambodia, Korea, Mongolia, Macao, Mexico, Malaysia, Nicaragua, New Zealand, Oman, Peru, French Polynesia, Philippines, Saint Pierre and Miquelon, Puerto Rico, Palau, Qatar, Singapore, El Salvador, Thailand, Timor-Leste, Tonga, Taiwan, United States of America, Venezuela, Vietnam\n",
        "\n",
        "[('Asia', 26), ('Latin_America', 10), ('South_America', 8), ('North_America', 4)]\n",
        "\n",
        "Component 2: explained var: 18.0411430842 countries: AE, AF, AO, BH, BJ, CI, CM, CV, CY, DZ, EG, JO, KW, NA, NG, OM, PR, PS, QA, SA, SD, SN, SY, SZ, TN, ZA, ZM\n",
        "United Arab Emirates, Afghanistan, Angola, Bahrain, Benin, Cote d'Ivoire, Cameroon, Cape Verde, Cyprus, Algeria, Egypt, Jordan, Kuwait, Namibia, Nigeria, Oman, Puerto Rico, Palestinian Territory, Qatar, Saudi Arabia, Sudan, Senegal, Syrian Arab Republic, Swaziland, Tunisia, South Africa, Zambia\n",
        "\n",
        "[('Africa', 11), ('Asia', 10), ('Middle_East', 4), ('Europe', 1), ('North_America', 1)]\n",
        "\n",
        "Component 3: explained var: 13.8243629393 countries: AD, AE, AG, AL, AR, AU, AX, AZ, BD, BH, BM, BO, BR, BS, BT, BW, BY, CA, CL, CO, CR, CZ, DO, EC, EG, FJ, GH, GM, GT, GU, HK, HN, ID, IL, IN, IS, JE, JP, KH, KR, KZ, LB, LT, LV, ME, MK, MN, MO, MX, MY, NG, NI, NZ, OM, PE, PF, PH, PM, PR, PW, QA, RU, SA, SG, SV, TH, TL, TO, TW, US, UZ, VE, VN, ZA, ZW\n",
        "Andorra, United Arab Emirates, Antigua and Barbuda, Albania, Argentina, Australia, \u00c5land Islands, Azerbaijan, Bangladesh, Bahrain, Bermuda, Bolivia, Brazil, Bahamas, Bhutan, Botswana, Belarus, Canada, Chile, Colombia, Costa Rica, Czech Republic, Dominican Republic, Ecuador, Egypt, Fiji, Ghana, Gambia, Guatemala, Guam, Hong Kong, Honduras, Indonesia, Israel, India, Iceland, Jersey, Japan, Cambodia, Korea, Kazakhstan, Lebanon, Lithuania, Latvia, Montenegro, Macedonia, Mongolia, Macao, Mexico, Malaysia, Nigeria, Nicaragua, New Zealand, Oman, Peru, French Polynesia, Philippines, Saint Pierre and Miquelon, Puerto Rico, Palau, Qatar, Russian Federation, Saudi Arabia, Singapore, El Salvador, Thailand, Timor-Leste, Tonga, Taiwan, United States of America, Uzbekistan, Venezuela, Vietnam, South Africa, Zimbabwe\n",
        "\n",
        "[('Asia', 34), ('Europe', 12), ('Latin_America', 10), ('South_America', 8), ('Africa', 6), ('North_America', 4), ('Middle_East', 1)]\n",
        "\n",
        "Component 4: explained var: 8.22722320828 countries: AD, AE, AL, AT, AX, AZ, BD, BE, BG, BH, BT, BW, BY, CH, CZ, DE, DK, EE, ES, FJ, GB, GH, GM, GR, GU, HU, ID, IE, IL, IN, IS, IT, JE, KH, KR, KW, KZ, LB, LT, LU, LV, MD, ME, MK, MN, MO, MY, N/A, NG, NL, NO, OM, PL, PW, QA, RO, RU, SA, SE, SI, TH, TL, UA, UZ, ZA, ZW\n",
        "Andorra, United Arab Emirates, Albania, Austria, \u00c5land Islands, Azerbaijan, Bangladesh, Belgium, Bulgaria, Bahrain, Bhutan, Botswana, Belarus, Switzerland, Czech Republic, Germany, Denmark, Estonia, Spain, Fiji, United Kingdom of Great Britain & Northern Ireland, Ghana, Gambia, Greece, Guam, Hungary, Indonesia, Ireland, Israel, India, Iceland, Italy, Jersey, Cambodia, Korea, Kuwait, Kazakhstan, Lebanon, Lithuania, Luxembourg, Latvia, Moldova, Montenegro, Macedonia, Mongolia, Macao, Malaysia, Nigeria, Netherlands, Norway, Oman, Poland, Palau, Qatar, Romania, Russian Federation, Saudi Arabia, Sweden, Slovenia, Thailand, Timor-Leste, Ukraine, Uzbekistan, South Africa, Zimbabwe\n",
        "\n",
        "[('Europe', 34), ('Asia', 25), ('Africa', 6)]\n",
        "\n",
        "Component 5: explained var: 4.2428857046 countries: AE, AF, AO, AU, BH, BJ, BS, CI, CL, CM, CV, CY, DZ, IE, IS, JO, LI, MA, NA, OM, PK, PR, PS, SD, SN, SY, SZ, TL, TN, ZM\n",
        "United Arab Emirates, Afghanistan, Angola, Australia, Bahrain, Benin, Bahamas, Cote d'Ivoire, Chile, Cameroon, Cape Verde, Cyprus, Algeria, Ireland, Iceland, Jordan, Liechtenstein, Morocco, Namibia, Oman, Pakistan, Puerto Rico, Palestinian Territory, Sudan, Senegal, Syrian Arab Republic, Swaziland, Timor-Leste, Tunisia, Zambia\n",
        "\n",
        "[('Asia', 10), ('Africa', 9), ('Europe', 4), ('Middle_East', 4), ('South_America', 1), ('Latin_America', 1), ('North_America', 1)]\n",
        "\n",
        "Component 6: explained var: 2.09284856671 countries: AE, AZ, BH, BS, BW, CL, CN, CR, CV, DO, EG, IR, IS, KW, LI, MA, MN, MX, NA, NG, PK, PM, PS, RS, SZ, TL, US, VN\n",
        "United Arab Emirates, Azerbaijan, Bahrain, Bahamas, Botswana, Chile, China, Costa Rica, Cape Verde, Dominican Republic, Egypt, Iran, Iceland, Kuwait, Liechtenstein, Morocco, Mongolia, Mexico, Namibia, Nigeria, Pakistan, Saint Pierre and Miquelon, Palestinian Territory, Serbia, Swaziland, Timor-Leste, United States of America, Vietnam\n",
        "\n",
        "[('Asia', 11), ('Africa', 5), ('Latin_America', 4), ('Europe', 3), ('Middle_East', 2), ('North_America', 2), ('South_America', 1)]\n",
        "\n",
        "Component 7: explained var: 1.8690566051 countries: AZ, BW, CN, DO, EG, ID, IR, KW, MA, MN, MX, NG, NI, PK, RS, TR, US, VE\n",
        "Azerbaijan, Botswana, China, Dominican Republic, Egypt, Indonesia, Iran, Kuwait, Morocco, Mongolia, Mexico, Nigeria, Nicaragua, Pakistan, Serbia, Turkey, United States of America, Venezuela\n",
        "\n",
        "[('Asia', 8), ('Middle_East', 2), ('Africa', 2), ('Latin_America', 2), ('North_America', 2), ('Europe', 1), ('South_America', 1)]\n",
        "\n",
        "Component 8: explained var: 1.31402936665 countries: AU, BT, CA, CN, CR, EE, FJ, GU, HK, ID, IR, JP, KH, MN, MO, NZ, PH, PM, PW, PY, TL, TR, VN\n",
        "Australia, Bhutan, Canada, China, Costa Rica, Estonia, Fiji, Guam, Hong Kong, Indonesia, Iran, Japan, Cambodia, Mongolia, Macao, New Zealand, Philippines, Saint Pierre and Miquelon, Palau, Paraguay, Timor-Leste, Turkey, Vietnam\n",
        "\n",
        "[('Asia', 18), ('Latin_America', 2), ('Europe', 1), ('South_America', 1), ('North_America', 1)]\n",
        "\n",
        "Component 9: explained var: 1.25000762718 countries: AG, AR, BM, BO, BS, CA, CO, CR, EC, EE, GT, HN, ID, IS, NI, PE, PF, PM, PR, SV, TO, TR, VE\n",
        "Antigua and Barbuda, Argentina, Bermuda, Bolivia, Bahamas, Canada, Colombia, Costa Rica, Ecuador, Estonia, Guatemala, Honduras, Indonesia, Iceland, Nicaragua, Peru, French Polynesia, Saint Pierre and Miquelon, Puerto Rico, El Salvador, Tonga, Turkey, Venezuela\n",
        "\n",
        "[('Latin_America', 9), ('South_America', 6), ('Asia', 4), ('Europe', 2), ('North_America', 2)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# look more into the data\n",
      "from math import fabs\n",
      "\n",
      "print site_cnt.shape\n",
      "\n",
      "# start by computing the average and standard deviation of censorship per site and per country\n",
      "means = []\n",
      "for index in range(len(sites)):\n",
      "    means.append(stats.tmean(site_cnt[:, index]))\n",
      "means.sort()\n",
      "#for start in range(0, len(sites), 8):\n",
      "    # print the means 5 to a line\n",
      "#    print \"{:< .3e} {:< .3e} {:< .3e} {:< .3e} {:< .3e} {:< .3e} {:< .3e} {:< .3e}\".format(*means[start:start + 8])\n",
      "diff = [x for x in range(len(sites)) if fabs(stats.tmean(site_cnt[:, index]) - 0.06030) < 0.00001]\n",
      "print len(diff)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(147, 569)\n",
        "0\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data exploration: Exploring the site vs country censored fraction plot\n",
      "\n",
      "#### How can we think about the data?\n",
      "* could we look at a lower granularity-> individual resolver level?\n",
      "  * probably not-> would be uneven between countries-> this represents the most even way to compare countries\n",
      "* what do we want to pull out of the data?\n",
      "  * blocking profiles/ similar sites-> groups of sites that are blocked similarly across countries?\n",
      "  * similar countries-> groups of countries that block similarly\n",
      "* so we want to do clustering on the data. How could we do that?\n",
      "  * hierarchical clustering-> go from individual clusters for each data point to larger clusters\n",
      "  * kmeans clustering-> find k good clusters\n",
      "* how can we find similar sites/ blocking profiles? (similar across countries)\n",
      "  * how to think about data\n",
      "    * each site is an observation we want to cluster, countries are features, and fractions are what we cluster on\n",
      "      * this representations selects for a) similar censorship fractions and b) similarity across multiple countries\n",
      "    * could view site as a distribution/ class and want to see what is similar-> each country is a different observation\n",
      "      * could look at correlation between sites-> weaker form of version above\n",
      "  * graph data\n",
      "    * cdf of std deviation and mean across sites for fraction of sites\n",
      "    * I want to visualize data to see if clustering makes sense. How to visualize 153 dim datapoints?\n",
      "      * could only look at censorship fractions larger than x percent and graph site vs country\n",
      "      * could also graph country vs fraction\n",
      "  * cluster data\n",
      "    * k means clustering on sites where each site is an observation, and treat countries as a feature vector."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# data exploration plotting\n",
      "# plot a bunch of cdfs to understand our data\n",
      "\n",
      "def create_cdf(data, x_label, y_label, title, filename, log=False,\n",
      "               invert=False):\n",
      "    \"\"\"Given a set of data, create a CDF of the data, optionally in log\n",
      "    format\n",
      "\n",
      "    \"\"\"\n",
      "    data.sort()\n",
      "    # create the y data for the CDF\n",
      "    if invert:\n",
      "        y_data = [float(x) / float(len(data)) for x in range(len(data), 0, -1)]\n",
      "    else:\n",
      "        y_data = [float(x) / float(len(data)) for x in range(len(data))]\n",
      "    fig, ax = plt.subplots()\n",
      "    plt.grid()\n",
      "    plt.plot(data, y_data)\n",
      "    plt.xlabel(x_label)\n",
      "    plt.ylabel(y_label)\n",
      "    if invert:\n",
      "        ax.invert_xaxis()\n",
      "\n",
      "    if log:\n",
      "        plt.xscale('log')\n",
      "\n",
      "    plt.title(title)\n",
      "    plt.savefig(filename, fmt='png')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# move onto clustering on the basis of pairwise correlation matrix\n",
      "from scipy.cluster import hierarchy as clust\n",
      "\n",
      "\n",
      "def compute_pdist_index(index1, index2, numElems):\n",
      "    \"\"\"Compute the appropriate pdist index to compare two elements\"\"\"\n",
      "    if index1 < index2:\n",
      "        maxIndex = index2\n",
      "        minIndex = index1\n",
      "    else:\n",
      "        maxIndex = index1\n",
      "        minIndex = index2\n",
      "        \n",
      "    base = minIndex*(numElems-1) - sum(range(minIndex)) - (minIndex+1)\n",
      "    return base + maxIndex\n",
      "\n",
      "# start by creating the pairwise correlation matrix\n",
      "def create_pairwise_correlation(mat):\n",
      "    site_cor = np.zeros(((len(sites) * len(sites) - 1), 1))\n",
      "    cor_indx = 0\n",
      "    for index in range(len(sites)):\n",
      "        for comp_indx in range(index + 1, len(sites)):\n",
      "            site_cor[cor_indx] = stats.pearsonr(mat[:, index], mat[:, comp_indx])[0]\n",
      "    return site_cor\n",
      "\n",
      "dists = create_pairwise_correlation(site_cnt)\n",
      "\n",
      "# start by visualizing the data-> create a \n",
      "\n",
      "# now do the clustering\n",
      "#linkage = clust.linkage(dists)\n",
      "\n",
      "# and finally, create a dendrogram\n",
      "#clust.dendrogram(dists)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/scipy/stats/stats.py:2436: RuntimeWarning: invalid value encountered in double_scalars\n",
        "  r = r_num / r_den\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.cluster.vq as vq\n",
      "from numpy.linalg import norm\n",
      "import time\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# do k means clustering where the observations are sites and the features are countries\n",
      "# this means that we need to take the transpose of the site_cnt matrix\n",
      "site_sim_mat = site_cnt.T\n",
      "\n",
      "def get_inter_dist(centroids):\n",
      "    \"\"\"Get the average distance between centroids\"\"\"\n",
      "    num_cents = centroids.shape[0]\n",
      "    dists = []\n",
      "    for index in range(num_cents):\n",
      "        cent1 = centroids[index, :]\n",
      "        for comp_index in range(index + 1, num_cents):\n",
      "            comp_cent = centroids[comp_index, :]\n",
      "            dists.append(norm(cent1 - comp_cent))\n",
      "    return stats.nanmean(dists)\n",
      "\n",
      "avg_dists_bw, avg_dist, ks = [], [], []\n",
      "k_vals = [1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 75, 100]\n",
      "#for k in k_vals:\n",
      "#for k in range(1, 50):\n",
      "for k in range(5, 50, 5):\n",
      "    start = time.time()\n",
      "    assign = vq.kmeans(site_sim_mat, k, iter=100)\n",
      "\n",
      "    # compute the average distance between clusters\n",
      "    avg_dist_bw_clusts = get_inter_dist(assign[0])\n",
      "    avg_dists_bw.append(avg_dist_bw_clusts)\n",
      "\n",
      "    # compute the average distortion\n",
      "    distortion = vq.vq(site_sim_mat, assign[0])[0]\n",
      "    avg_distort = stats.nanmean(distortion)\n",
      "    avg_dist.append(avg_distort)\n",
      "    ks.append(k)\n",
      "    \n",
      "    print time.time() - start, avg_dist_bw_clusts, avg_distort\n",
      "\n",
      "# graph cdfs of the cluster info\n",
      "#filename = \"global-censorship-results-site-kmeans-avg-distort.png\"\n",
      "xlabel = \"Values of k\"\n",
      "ylabel = \"Average distortion from closest cluster\"\n",
      "title = \"Average distortion for different choices of k\"\n",
      "fig = plt.figure()\n",
      "plt.plot(ks, avg_dist)\n",
      "plt.title(title)\n",
      "plt.xlabel(xlabel)\n",
      "plt.ylabel(ylabel)\n",
      "\n",
      "fig = plt.figure()\n",
      "ylabel = \"Average distance between centroids\"\n",
      "title = \"Average distance between centroids for choices of k\"\n",
      "plt.plot(ks, avg_dists_bw)\n",
      "plt.title(title)\n",
      "plt.xlabel(xlabel)\n",
      "plt.ylabel(ylabel)\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.12736487389 4.69447494703 2.65541417814\n",
        "12.445428133"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.72664750335 4.75538821085\n",
        "17.9652311802"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.22415066495 7.61412620099\n",
        "23.1577768326"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.74601724991 6.41158140743\n",
        "33.4634268284"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.16052162238 12.3632822643\n",
        "48.9505839348"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.920010757 16.2352635679\n",
        "52.680603981"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.75233961671 15.6356790444\n",
        "61.6909790039"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.95629720623 20.8844455985\n",
        "75.7948081493"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.63478857258 23.4668917164\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr1 = np.array([1,2,3])\n",
      "arr2 = np.array([1,2,3])\n",
      "print np.dot(arr1, arr2)\n",
      "\n",
      "#print np.linalg.norm(arr1, arr2)\n",
      "print np.linalg.norm(arr1 - arr2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = np.array(site_cnt, copy=True)\n",
      "print site_cnt[0][0]\n",
      "b[0][0] += 1\n",
      "print b[0][0]\n",
      "print site_cnt[0][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-0.259954034455\n",
        "0.740045965545\n",
        "-0.259954034455\n"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}